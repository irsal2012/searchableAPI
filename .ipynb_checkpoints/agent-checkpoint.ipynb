{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from googlesearch import search\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import os\n",
    "from io import BytesIO\n",
    "from PyPDF2 import PdfReader\n",
    "from reference import llm\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # messages have the type \"list\".\n",
    "    # The add_messages function appends messages to the list, rather than overwriting them\n",
    "    messages: Annotated[list, add_messages]\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "#The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever the node is used.’’’\n",
    "#graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_data):\n",
    "    try:\n",
    "        pdf_reader = PdfReader(BytesIO(pdf_data))\n",
    "        text = \"\"\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract text from a Word document (.docx)\n",
    "def extract_text_from_docx(docx_data):\n",
    "    try:\n",
    "        doc = Document(BytesIO(docx_data))\n",
    "        text = \"\"\n",
    "        for para in doc.paragraphs:\n",
    "            text += para.text + \"\\n\"\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from DOCX: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract text from a text file\n",
    "def extract_text_from_txt(txt_data):\n",
    "    return txt_data.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to summarize text using LangChain and GPT-4\n",
    "def summarize_text_with_langchain(text):\n",
    "    try:\n",
    "        # Create a prompt template for summarization\n",
    "        prompt_template = \"Please summarize the following text:\\n\\n{text}\"\n",
    "        prompt = PromptTemplate(input_variables=[\"text\"], template=prompt_template)\n",
    "        \n",
    "        # Create the LLM chain\n",
    "        chain = LLMChain(llm=llm, prompt=prompt)\n",
    "        \n",
    "        # Get the summary from the model\n",
    "        summary = chain.run(text)\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        print(f\"Error summarizing with LangChain: {e}\")\n",
    "        return \"Error generating summary.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11d2ecfe0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Function to find downloadable files from a URL\n",
    "def find_downloadable_links(url):\n",
    "    try:\n",
    "        # Send HTTP request to the URL\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Check if the request was successful\n",
    "\n",
    "        # Parse the page content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find all links in the page\n",
    "        links = soup.find_all('a', href=True)\n",
    "\n",
    "        downloadable_files = []\n",
    "        \n",
    "        # Check if the link points to a downloadable file (e.g., .pdf, .docx, .txt)\n",
    "        for link in links:\n",
    "            href = link['href']\n",
    "            if href.endswith(('.pdf', '.docx', '.txt', '.xls', '.pptx', '.csv')):\n",
    "                downloadable_files.append(href)\n",
    "\n",
    "        return downloadable_files\n",
    "    except Exception as e:\n",
    "        print(f\"Error with URL {url}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Function to download the document content\n",
    "def download_document(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading document from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to get a summary of the document\n",
    "def get_document_summary(url):\n",
    "    # Download the document based on its extension\n",
    "    document_data = download_document(url)\n",
    "    \n",
    "    if not document_data:\n",
    "        return \"Unable to download the document.\"\n",
    "\n",
    "    # Check the file type by extension and extract text accordingly\n",
    "    if url.endswith(\".pdf\"):\n",
    "        text = extract_text_from_pdf(document_data)\n",
    "    elif url.endswith(\".docx\"):\n",
    "        text = extract_text_from_docx(document_data)\n",
    "    elif url.endswith(\".txt\"):\n",
    "        text = extract_text_from_txt(document_data)\n",
    "    else:\n",
    "        return \"Unsupported file type for summarization.\"\n",
    "\n",
    "    # If no text extracted, return a message\n",
    "    if not text.strip():\n",
    "        return \"No text extracted from the document.\"\n",
    "\n",
    "    # Summarize the extracted text using LangChain and GPT-4\n",
    "    return summarize_text_with_langchain(text)\n",
    "\n",
    "# Function to perform the search and get the links to documents\n",
    "def search_documents(query, num_results=5):\n",
    "    print(f\"Searching for '{query}'...\")\n",
    "    \n",
    "    # Perform Google search and get the URLs of the top results\n",
    "    search_results = search(query, num_results=num_results)\n",
    "\n",
    "    all_downloadable_links = {}\n",
    "\n",
    "    # Check each URL for downloadable files\n",
    "    for result in search_results:\n",
    "        print(f\"Checking {result}...\")\n",
    "        downloadable_links = find_downloadable_links(result)\n",
    "        if downloadable_links:\n",
    "            all_downloadable_links[result] = downloadable_links\n",
    "\n",
    "    return all_downloadable_links\n",
    "\n",
    "graph_builder.add_node(\"search_documents\", search_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11d2ecfe0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set entry and finish points\n",
    "graph_builder.set_entry_point(\"search_documents\")\n",
    "graph_builder.set_finish_point(\"search_documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = graph_builder.compile()\n",
    "from IPython.display import Image, display\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  iLet AND Beta Bionics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for 'iLet AND Beta Bionics'...\n",
      "Checking https://www.betabionics.com/...\n",
      "Checking https://www.betabionics.com/ilet-bionic-pancreas/...\n",
      "Checking https://www.betabionics.com/hcp/...\n",
      "Checking https://www.adces.org/education/danatech/insulin-pumps/find-and-compare-insulin-pumps/product-detail/the-ilet-bionic-pancreas...\n",
      "Checking https://consumerguide.diabetes.org/products/ilet-bionic-pancreas-system...\n",
      "Checking https://www.betabionics.com/beta-bionics-announces-partnership-with-abbott-to-integrate-the-ilet-bionic-pancreas-with-the-freestyle-libre-3-plus-icgm/...\n",
      "Checking https://www.betabionics.com/beta-bionics-announces-launch-of-the-ilet-bionic-pancreas-with-abbotts-freestyle-libre-3-plus-sensor/...\n",
      "Checking https://pmc.ncbi.nlm.nih.gov/articles/PMC8247518/...\n",
      "Error with URL https://pmc.ncbi.nlm.nih.gov/articles/PMC8247518/: 403 Client Error: Forbidden for url: https://pmc.ncbi.nlm.nih.gov/articles/PMC8247518/\n",
      "Checking https://www.betabionics.com/user-resources/bionic_circle/...\n",
      "Checking https://www.betabionics.com/get-started/im-ready-to-get-started/...\n",
      "\n",
      "Found downloadable files at these links:\n",
      "\n",
      "URL: https://www.adces.org/education/danatech/insulin-pumps/find-and-compare-insulin-pumps/product-detail/the-ilet-bionic-pancreas\n",
      "  - https://www.betabionics.com/wp-content/uploads/LA000081_D-iLet-User-Guide.pdf\n",
      "Error downloading document from https://www.betabionics.com/wp-content/uploads/LA000081_D-iLet-User-Guide.pdf: 404 Client Error: Not Found for url: https://www.betabionics.com/wp-content/uploads/LA000081_D-iLet-User-Guide.pdf\n",
      "    Summary: Unable to download the document.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  machine learning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for 'machine learning'...\n",
      "Checking https://en.wikipedia.org/wiki/Machine_learning...\n",
      "Checking https://www.ibm.com/think/topics/machine-learning...\n",
      "Checking https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained...\n",
      "Checking https://developers.google.com/machine-learning/crash-course...\n",
      "Checking https://www.coursera.org/learn/machine-learning...\n",
      "Checking https://www.geeksforgeeks.org/machine-learning/...\n",
      "Checking https://www.google.com/search?num=12...\n",
      "Checking https://www.databricks.com/glossary/machine-learning-models...\n",
      "Checking https://azure.microsoft.com/en-us/products/machine-learning...\n",
      "Checking https://www.w3schools.com/python/python_ml_getting_started.asp...\n",
      "\n",
      "Found downloadable files at these links:\n",
      "\n",
      "URL: https://en.wikipedia.org/wiki/Machine_learning\n",
      "  - https://web.cs.umass.edu/publication/docs/1981/UM-CS-1981-028.pdf\n",
      "    Summary: No text extracted from the document.\n",
      "  - https://web.archive.org/web/20210225070218/https://web.cs.umass.edu/publication/docs/1981/UM-CS-1981-028.pdf\n",
      "Error extracting text from PDF: EOF marker not found\n",
      "    Summary: No text extracted from the document.\n",
      "  - http://www.eng.tau.ac.il/~bengal/28.pdf\n",
      "Error downloading document from http://www.eng.tau.ac.il/~bengal/28.pdf: 400 Client Error: Bad Request for url: https://www.iradbengal.sites.tau.ac.il/28.pdf\n",
      "    Summary: Unable to download the document.\n",
      "  - https://web.archive.org/web/20090709143601/http://www.eng.tau.ac.il/~bengal/28.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vc/fs2hbmss52b3lhjkh11_ppbndjv4_1/T/ipykernel_40133/3944587544.py:9: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt)\n",
      "/var/folders/vc/fs2hbmss52b3lhjkh11_ppbndjv4_1/T/ipykernel_40133/3944587544.py:12: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  summary = chain.run(text)\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Summary: The paper \"Measuring the Efficiency of the Intraday Forex Market with a Universal Data Compression Algorithm\" by Armin Shmilovici et al. explores the use of a universal Variable Order Markov (VOM) model to test the weak form of the Efficient Market Hypothesis (EMH) in the intraday Forex market. The study analyzes 12 pairs of international currency exchange rates over various time intervals (1 to 30 minutes) for one year. The VOM model, which is a data compression algorithm, is used to detect recurring patterns in the data, which can be used for both compression and prediction.\n",
      "\n",
      "The study finds statistically significant compression in all time-series, indicating that the Forex market is not entirely random and that some patterns can be predicted above random chance. However, the predictability is not sufficient to develop a profitable trading strategy, suggesting that the Forex market is efficient most of the time. The paper concludes that while the VOM model can detect patterns and predict trends to some extent, these do not translate into consistent excess returns due to transaction costs and market frictions, thus supporting the EMH. The study also highlights the limitations of the VOM model, such as its reliance on discrete data and the need for further optimization.\n",
      "  - http://www.eng.tau.ac.il/~bengal/Journal%20Paper.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading document from http://www.eng.tau.ac.il/~bengal/Journal%20Paper.pdf: 400 Client Error: Bad Request for url: https://www.iradbengal.sites.tau.ac.il/Journal-Paper.pdf\n",
      "    Summary: Unable to download the document.\n",
      "  - https://web.archive.org/web/20170813153615/http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2011_CoatesNL11.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Summary: The paper \"An Analysis of Single-Layer Networks in Unsupervised Feature Learning\" by Adam Coates, Honglak Lee, and Andrew Y. Ng explores the effectiveness of single-layer networks in unsupervised feature learning. The authors argue that simple factors, such as the number of hidden nodes, can be more crucial for high performance than the complexity of the learning algorithm or model depth. They apply various off-the-shelf feature learning algorithms, including sparse auto-encoders, sparse RBMs, K-means clustering, and Gaussian mixtures, to datasets like CIFAR, NORB, and STL using single-layer networks. The study finds that large numbers of hidden nodes and dense feature extraction are critical for achieving high performance, with K-means clustering surprisingly yielding state-of-the-art results on CIFAR-10 and NORB datasets. The paper emphasizes that focusing on network parameters like whitening, feature count, stride, and receptive field size can significantly impact performance, sometimes more than the choice of the learning algorithm itself. The authors conclude that simple, fast algorithms can be highly competitive when combined with optimal network parameters.\n",
      "  - http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2011_CoatesNL11.pdf\n",
      "Error downloading document from http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2011_CoatesNL11.pdf: HTTPConnectionPool(host='machinelearning.wustl.edu', port=80): Max retries exceeded with url: /mlpapers/paper_files/AISTATS2011_CoatesNL11.pdf (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x12eaa4ec0>: Failed to resolve 'machinelearning.wustl.edu' ([Errno 8] nodename nor servname provided, or not known)\"))\n",
      "    Summary: Unable to download the document.\n",
      "  - https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/csurka-eccv-04.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Summary: The paper presents a novel method for generic visual categorization, which involves identifying the object content of natural images while generalizing across variations inherent to the object class. The proposed \"bag of keypoints\" method is based on vector quantization of affine invariant descriptors of image patches. Two implementations using different classifiers, Naïve Bayes and SVM, are compared. The method is simple, computationally efficient, and invariant to affine transformations, occlusion, lighting, and intra-class variations. The approach is evaluated on a seven-category dataset, demonstrating robustness to background clutter and good categorization accuracy without exploiting geometric information. The method involves detecting and describing image patches, assigning patch descriptors to clusters, constructing a bag of keypoints, and applying a multi-class classifier. The paper also discusses the distinction between visual categorization and related problems like recognition, content-based image retrieval, and detection. The method is inspired by text categorization approaches and is evaluated using performance measures like confusion matrix, overall error rate, and mean ranks. The results show that the SVM outperforms Naïve Bayes, and the method is effective even with background clutter and multiple objects in images. Future work includes extending the method to incorporate geometric information and handle objects occupying a small fraction of the field of view.\n",
      "  - https://web.archive.org/web/20190713040210/http://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/csurka-eccv-04.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Summary: The paper presents a novel method for generic visual categorization using a \"bag of keypoints\" approach, which involves vector quantization of affine invariant descriptors of image patches. The method is simple, computationally efficient, and invariant to affine transformations, occlusion, lighting, and intra-class variations. Two classifiers, Naïve Bayes and SVM, are compared, with SVM showing superior performance. The method is tested on a seven-class dataset and a four-class dataset, demonstrating robustness to background clutter and good categorization accuracy without geometric information. The approach is inspired by text categorization methods and involves detecting and describing image patches, assigning descriptors to clusters, constructing a bag of keypoints, and applying a multi-class classifier. The paper highlights the potential for extending the method to incorporate geometric information and handle objects occupying small fractions of the field of view.\n",
      "  - http://www.dsp.utoronto.ca/~haiping/Publication/SurveyMSL_PR2011.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Summary: The paper \"A Survey of Multilinear Subspace Learning for Tensor Data\" by Haiping Lu, K. N. Plataniotis, and A. N. Venetsanopoulos provides a comprehensive overview of multilinear subspace learning (MSL) for dimensionality reduction of multidimensional data represented as tensors. It addresses the increasing need for effective learning algorithms due to the massive generation of multidimensional data in various applications. The paper discusses the foundational aspects of MSL, including multilinear projections, a unifying MSL framework, algorithmic solutions, and categorization of unsupervised and supervised MSL algorithms. It also highlights a range of MSL applications, such as face and gait recognition, music genre classification, EEG signal classification, anomaly detection, and visual content analysis. The paper concludes with insights into future research directions, emphasizing the development of new MSL solutions and exploration of new applications.\n",
      "  - https://web.archive.org/web/20190710225429/http://www.dsp.utoronto.ca/~haiping/Publication/SurveyMSL_PR2011.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:1043\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1043\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_models.py:761\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[0;32m--> 761\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m             \u001b[38;5;66;03m# Get a summary of each file\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m             summary \u001b[38;5;241m=\u001b[39m get_document_summary(file)\n\u001b[1;32m     20\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Summary: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msummary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[5], line 60\u001b[0m, in \u001b[0;36mget_document_summary\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo text extracted from the document.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Summarize the extracted text using LangChain and GPT-4\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m summarize_text_with_langchain(text)\n",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m, in \u001b[0;36msummarize_text_with_langchain\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      9\u001b[0m     chain \u001b[38;5;241m=\u001b[39m LLMChain(llm\u001b[38;5;241m=\u001b[39mllm, prompt\u001b[38;5;241m=\u001b[39mprompt)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Get the summary from the model\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     summary \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39mrun(text)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m summary\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:181\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     emit_warning()\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain/chains/base.py:606\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    605\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    607\u001b[0m         _output_key\n\u001b[1;32m    608\u001b[0m     ]\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    612\u001b[0m         _output_key\n\u001b[1;32m    613\u001b[0m     ]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:181\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     emit_warning()\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain/chains/base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    387\u001b[0m }\n\u001b[0;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m    390\u001b[0m     inputs,\n\u001b[1;32m    391\u001b[0m     cast(RunnableConfig, {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}),\n\u001b[1;32m    392\u001b[0m     return_only_outputs\u001b[38;5;241m=\u001b[39mreturn_only_outputs,\n\u001b[1;32m    393\u001b[0m     include_run_info\u001b[38;5;241m=\u001b[39minclude_run_info,\n\u001b[1;32m    394\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain/chains/base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain/chains/base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain/chains/llm.py:126\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    123\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    124\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    125\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 126\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate([inputs], run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain/chains/llm.py:138\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    136\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[1;32m    139\u001b[0m         prompts,\n\u001b[1;32m    140\u001b[0m         stop,\n\u001b[1;32m    141\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs,\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[1;32m    146\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[1;32m    147\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:791\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    785\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    789\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    790\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:638\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    637\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 638\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[1;32m    639\u001b[0m                 m,\n\u001b[1;32m    640\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    641\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    642\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    643\u001b[0m             )\n\u001b[1;32m    644\u001b[0m         )\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    646\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:856\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 856\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[1;32m    857\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    858\u001b[0m         )\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    860\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:790\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 790\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n\u001b[1;32m    791\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/resources/chat/completions.py:850\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    847\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    848\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    849\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 850\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m    851\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    852\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[1;32m    853\u001b[0m             {\n\u001b[1;32m    854\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m    855\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m    856\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[1;32m    857\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m    858\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m    859\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m    860\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m    861\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[1;32m    862\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[1;32m    863\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m    864\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    865\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[1;32m    866\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m    867\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[1;32m    868\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[1;32m    869\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m    870\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[1;32m    871\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m    872\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m    873\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[1;32m    874\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m    875\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[1;32m    876\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m    877\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[1;32m    878\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m    879\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m    880\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m    881\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m    882\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m    883\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m    884\u001b[0m             },\n\u001b[1;32m    885\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[1;32m    886\u001b[0m         ),\n\u001b[1;32m    887\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m    888\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    889\u001b[0m         ),\n\u001b[1;32m    890\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m    891\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    892\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[1;32m    893\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:1283\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1271\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1279\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1280\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1281\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1282\u001b[0m     )\n\u001b[0;32m-> 1283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:960\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    961\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    962\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    963\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    964\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    965\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m    966\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:1049\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1048\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1049\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[1;32m   1050\u001b[0m         input_options,\n\u001b[1;32m   1051\u001b[0m         cast_to,\n\u001b[1;32m   1052\u001b[0m         retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1053\u001b[0m         response_headers\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m   1054\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1055\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1056\u001b[0m     )\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:1096\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1092\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m.\u001b[39murl, timeout)\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m-> 1096\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m   1099\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1100\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1103\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1104\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the search\n",
    "while True:\n",
    "    user_input = \"machine learning model\" #input(\"User: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "#    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "#        for value in event.values():\n",
    "#            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "    downloadable_files = search_documents(user_input, num_results=10)\n",
    "\n",
    "    if downloadable_files:\n",
    "        print(\"\\nFound downloadable files at these links:\")\n",
    "        for url, files in downloadable_files.items():\n",
    "            print(f\"\\nURL: {url}\")\n",
    "            for file in files:\n",
    "                print(f\"  - {file}\")\n",
    "                # Get a summary of each file\n",
    "                summary = get_document_summary(file)\n",
    "                print(f\"    Summary: {summary}\")\n",
    "    else:\n",
    "        print(\"No downloadable files found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
