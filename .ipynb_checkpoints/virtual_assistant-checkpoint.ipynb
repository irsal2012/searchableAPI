{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Transformer architecture, as introduced in the paper 'Attention Is All You Need,' is a novel network architecture that relies on self-attention mechanisms\n",
      "rather than recurrent or convolutional neural networks. The model is composed of an encoder and a decoder, each consisting of a stack of identical layers. Each\n",
      "layer in the encoder has two sub-layers: a multi-head self-attention mechanism and a position-wise fully connected feed-forward network. The decoder has an\n",
      "additional sub-layer that performs multi-head attention over the encoder's output.  One of the key innovations of the Transformer is its ability to process\n",
      "sequences in parallel, which significantly reduces training time compared to models that rely on sequential processing. This parallelization is achieved through\n",
      "the self-attention mechanism, which allows the model to weigh the importance of different words in a sentence, regardless of their position.  The Transformer\n",
      "has set new benchmarks in translation quality and has been widely adopted in various applications beyond language processing, including image processing and\n",
      "more.\n",
      "\n",
      "Document ID: 1706.03762, Title: Attention Is All You Need, Authors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez,\n",
      "Lukasz Kaiser, Illia Polosukhin, Link: http://arxiv.org/pdf/1706.03762\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from virtual_assistant import createAgent\n",
    "from contextlib import redirect_stdout\n",
    "import textwrap\n",
    "\n",
    "input_query = 'Can you tell me what transformer architecture is?'\n",
    "runnable = createAgent()\n",
    "with redirect_stdout(io.StringIO()):  # Suppress the intermediate output\n",
    "    output = runnable.invoke({\n",
    "        'input': input_query,\n",
    "        'chat_history': [],\n",
    "    })\n",
    "\n",
    "# Extract the main body from the last intermediate step\n",
    "main_body = output['intermediate_steps'][-1].tool_input.get('main_body')\n",
    "sources = output['intermediate_steps'][-1].tool_input.get('sources')\n",
    "\n",
    "# Wrap the text to a specified width (e.g., 80 characters per line)\n",
    "wrapped_output = textwrap.fill(main_body, width=160)\n",
    "source_wrapped_out = textwrap.fill(sources, width=160)\n",
    "print(wrapped_output + '\\n\\n' + source_wrapped_out)\n",
    "#print('\\n'+source_wrapped_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".searching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
